---
title: DSAN 5500 Final Project Job Position ETL Pipeline
subtitle: A DSAN 5500
author: Jen Guo and Wendy Hu
date: last-modified
date-format: long
format:
  html:
    toc: true
    code-copy: true
    code-overflow: wrap
    mainfont: Atkinson Hyperlegible
    code-annotations: hover
    code-fold: true
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
  freeze: auto 
jupyter: python3
---

# Set Up API Key

```{python}
#load needed packages
import json
import os
import requests

#retrieve API key from stored json file
try:
    with open('Jen_api.json') as f:
        keys = json.load(f)
    
        #store API key and app_id
        APP_ID = keys['app_id']
        API_KEY = keys['api_key']
        
#handle errors if json file not found and if api key is not valid
except FileNotFoundError:
    print("The file storing api key was not found.")
except KeyError as e:
    print(f"Missing key in json file: {e}")
except json.JSONDecodeError:
    print("Error reading json file.")
```

# Test 1 extract, transform, and print out job postions

```{python}
# Define your search parameters
# params = {
#     'app_id': APP_ID,
#     'app_key': API_KEY,
#     'what': 'data scientist',          # Job title or keywords
#     'where': 'Washington, DC',         # Location
#     'results_per_page': 2,             # Number of results per page
#     # 'sort_by': 'date'                  # Sort by most recent
# }
```

```{python}
#define url site on Adzuna to scrape job position posts
# url = 'https://api.adzuna.com/v1/api/jobs/us/search/1'

```

```{python}
# Make the request
# response = requests.get(url, params=params)

```

```{python}
# Check response
# if response.status_code == 200:
#     data = response.json()
#     for job in data.get('results', []):
#         print('🧾 Job Title:', job.get('title'))
#         print('🏢 Company:', job.get('company', {}).get('display_name'))
#         print('📍 Location:', job.get('location', {}).get('display_name'))
#         print('📝 Description:', job.get('description')[:150], '...')
#         print('🔗 URL:', job.get('redirect_url'))
#         print('-' * 80)
# else:
#     print('Failed to retrieve jobs:', response.status_code)
#     print(response.text)
```

# Test 2 with BaseModel class ETL

# Extract Step

```{python}
#install needed packages
from pprint import pprint
from typing import List, Optional, Union
import string

#from bs4 import BeautifulSoup
from pydantic import BaseModel, field_validator, HttpUrl, ValidationError, FilePath

#define GetJobs class
class GetJobs(BaseModel):
  #intialize variables in GetJobs class types
  title: str
  company: str
  location: str
  salary: Optional[Union[int, float, str]]
  salary_min: int
  contract_time: str
  degree: str
  description: str
  responsibilities: str
  about_url: HttpUrl

  #validator to clean the extracted salary to replace "$" and "," symbols to convert to integer
  @field_validator('salary')
  @classmethod
  def clean_salary(cls, value):
      #if the extracted salary is integer or float value then return the salary value
      if isinstance(value,(int, float)):
          return value
      #if the extracted salary is string type then remove the "$" and the "," symbols
      if isinstance(value, str):
          cleaned_sal = value.replace("$", "").replace(",", "").strip()
          #handle errors for string type extracted salary
          try:
              return int(float(cleaned_sal))
          except ValueError:
              return "Not specified"
          return "Not specified"
          
  #validator for salary_min so it's always a clean int format
  @field_validator('salary_min', mode='before')
  @classmethod
  def convert_salary_min(cls, value):
      if isinstance(value, float):
          return round(value) #return rounded conversion of salary min value
      return value
 
      
  #validator for extracted location to replace "," symbol
  @field_validator('location')
  @classmethod
  def clean_location(cls, value: str):
    return value.replace("“","").replace("”","")


#define API request parameters
params = {
    'app_id': APP_ID,                  # app ID
    'app_key': API_KEY,                # API key
    'what': 'data scientist',          # Job title or keywords
    'where': 'Washington, DC',         # Location
    'results_per_page': 1,             # Number of results per page
    'sort_by': 'date',                 # Sort by most recent
    'salary_min': 50000,               # Minimum salary to get results for
    'full_time': 1                     # Only return full-time job positions
}

#create extract_jobs function to extract job posts
def extract_jobs(job_url: HttpUrl) -> List[GetJobs]:
  response = requests.get(job_url, params=params) #request from the Adzuna job post page using the request library
  #print error message if could not fetch job posts from page
  if response.status_code != 200:
      raise Exception(f"Failed to fetch jobs: {response.status_code}")

  #get job posts in json format
  jobs_data = response.json()
  #initialize empty list to store extracted job posts
  extracted_jobs = []

  #for each of the extracted job posts
  for job in jobs_data.get("results", []):
      try:
          job_post = GetJobs( #call GetJobs class
              title = job.get("title", "No title"), #extract the job title of the job position post
              company = job.get("company", {}).get("display_name", "Unknown"), #extract the company name of the job position post
              location = job.get("location", {}).get("display_name", "Unknown"), #extract the job location of the job position post
              salary = job.get("salary", "Not specified"), #extract the job salary information of the job position post
              salary_min = round(job.get("salary_min", 0)), #extract the minimum salary for the job position
              contract_time = job.get("contract_time", "Unknown"), #extract employment hours from job position post
              degree = job.get("degree", "Unknown"), #extract the work hours ex. Full-time, part time for the job position post
              description = job.get("description", "")[:250], #extract the job description of the job post
              responsibilities = job.get("description", "")[:250], #extract the responsibilities, fall back to description if no separate responsibilities found
              about_url = job.get("redirect_url")) #extract the url page of job post
          
          extracted_jobs.append(job_post) #add extracted job to list
      except ValidationError as e: #raise error if job wasn't able to get extracted
          print(f"Validation error: {e}")
          
  return extracted_jobs #return extracted job posts with the requested parameters
          

```

# Transformation Step

```{python}
#create function to transform extract job info into a friendly email structure
def transform_extracted_jobs(job_obj: List[GetJobs]) -> str:
    #if no job post extracted then return error message
    if not job_obj:
        return "No job posts found."

    #set text for email body
    email_body = "Your Daily Job Digest: Data Scientist roles in Washington, DC*\n\n"

    #iterate over extracted job to be displayed in the following format
    for i, job in enumerate(job_obj, start=1):
        job_entry = (
            f"Title {i}: {job.title}**\n"                   #print job title
            f"Company: {job.company}\n"                     #print company name
            f"Location: {job.location}\n"                   #print location of company
            f"Salary: {job.salary}\n"                       #print job salary
            f"Minimum salary: {job.salary_min}\n"          #print job minimum salart
            f"Employment type: {job.contract_time}\n"       #print job type in terms of full-time. part-time, internship
            f"Degree requirement: {job.degree}\n"           #print education requirement for job post
            f"Description summary: {job.description}\n"     #print job description
            f"Responsibilities: {job.responsibilities}\n"   #print job responsibilites
            f"More info url: {job.about_url})\n\n"          #print url of the job post
        )
        email_body += job_entry #append the job_entry to email_body
    return email_body #return the email_body
        
```

# Load Step

```{python}
#create function to load the extracted job posts in email format into a json file as test 
def load_jobs_to_file(job_str: str, load_filepath: str) -> None:
    with open(load_filepath, 'a') as file:
        file.write(job_str + '\n')

def load_jobs_as_json(job_list: List[GetJobs], filepath: str):
    with open(filepath, 'w') as f:
        json.dump([job.model_dump(mode="json") for job in job_list], f, indent=2)
```

```{python}
#create function to define url to extract job posts
def scrape_job(
    job_url: str = "https://api.adzuna.com/v1/api/jobs/us/search/1", #extract job posts from this Adzuna url
    jobs_filename: str = "extracted_jobs.json" #load extracted data to json file with specified title
):
  extracted_jobs = extract_jobs(job_url) #call the extract_jobs function

  #add the transformatiom_extracted_jobs function step
  email_template = transform_extracted_jobs(extracted_jobs)
  #print out the email_friendly version of extracted jobs in email template
  print(email_template)

  #file_result = load_jobs_to_file(email_template, jobs_filename)
  #return(file_result) #return extracted job posts in the json file output
  load_jobs_to_file(email_template, jobs_filename)

# scrape_job() #call the scrape_job function
```

```{python}
def scrape_job(
    job_url: str = "https://api.adzuna.com/v1/api/jobs/us/search/1", 
    jobs_filename: str = "extracted_jobs_structured.json"
):
    extracted_jobs = extract_jobs(job_url)
    
    # Save structured JSON
    load_jobs_as_json(extracted_jobs, jobs_filename)
    
    # Transform for email content
    email_template = transform_extracted_jobs(extracted_jobs)
    return email_template  # return text for the email

scrape_job()
```
    J

```{python}
import smtplib
from email.message import EmailMessage

def send_email_smtp(subject: str, body: str, to_email: str,
                    from_email: str, app_password: str,
                    attachment_path: str = None):
    msg = EmailMessage()
    msg.set_content(body)
    msg['Subject'] = subject
    msg['From'] = from_email
    msg['To'] = to_email

    # Add attachment if provided
    if attachment_path:
        with open(attachment_path, 'rb') as f:
            file_data = f.read()
            file_name = os.path.basename(attachment_path)
        msg.add_attachment(file_data, maintype='application', subtype='json', filename=file_name)

    # Send
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:
            smtp.login(from_email, app_password)
            smtp.send_message(msg)
            print("Email sent successfully!")
    except Exception as e:
        print(f"Failed to send email: {e}")
```


```{python}
from dotenv import load_dotenv
import os

load_dotenv(dotenv_path="./.env")

app_password = os.getenv("GMAIL_APP_PASSWORD")
# print("App password loaded:", app_password)
```


```{python}
email_content = scrape_job(
    job_url="https://api.adzuna.com/v1/api/jobs/us/search/1",
    jobs_filename="extracted_jobs_structured.json"
)

send_email_smtp(
    subject="🧾 Your Daily Data Scientist Job Digest",
    body=email_content,
    to_email="liwen881129@gmail.com",
    from_email="wendy881129@gmail.com",
    app_password=app_password,
    attachment_path="extracted_jobs_structured.json"
)

```